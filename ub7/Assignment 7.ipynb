{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "* Leon Sixt\n",
    "* Benjamin Wild\n",
    "\n",
    "Note: We implemented the whole SIFT paper and also PCA-SIFT [1] to improve the results after the perspective transformation. \n",
    "\n",
    "[1] Ke, Yan, and Rahul Sukthankar. \"PCA-SIFT: A more distinctive representation for local image descriptors.\" Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on. Vol. 2. IEEE, 2004."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "[Jump to the interesting parts](#scale_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "import base64\n",
    "import math\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from skimage.filters import gaussian_filter, scharr_h, scharr_v\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.transform import resize, rotate\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "import glob\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import scipy.misc\n",
    "from scipy.signal import convolve\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import itertools\n",
    "from itertools import tee, islice\n",
    "import imageio\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "import seaborn as sns\n",
    "from more_itertools import pairwise\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sift_circles(keypoints_pyr, orientation_pyr=None, figure=None, ):\n",
    "    if figure is None:\n",
    "        figure=plt\n",
    "        \n",
    "    for s, keypoints in enumerate(scale_points_pyramid(keypoints_pyr)):\n",
    "        x, y = keypoints[:, 2], keypoints[:, 1]\n",
    "        radius = 5*(s+1) + 2*s**2\n",
    "        for i, p in enumerate(keypoints):\n",
    "            circle = plt.Circle((p[2], p[1]), radius, color='r', fill=False, lw=1.5)\n",
    "            figure.add_artist(circle)\n",
    "            \n",
    "            if orientation_pyr is not None:\n",
    "                theta = orientation_pyr[s][i]\n",
    "                x = np.sin(theta) * radius + p[2]\n",
    "                y = np.cos(theta) * radius + p[1]\n",
    "                line = plt.Line2D((p[2], x), (p[1], y), color='r')\n",
    "                figure.add_artist(line)\n",
    "            \n",
    "def scale_points_pyramid(points_pyr):\n",
    "    return [scale_points(points, s) for s, points in enumerate(points_pyr)]\n",
    "        \n",
    "def scale_points(points, s):\n",
    "    return np.concatenate([points[:, :1], points[:, 1:3] * (2 ** s)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_initial_keypoints(sift, results):\n",
    "    fig_before, axes_before = plt.subplots(1, sift.num_octaves, figsize=(16, 4))\n",
    "    fig_after, axes_after = plt.subplots(1, sift.num_octaves, figsize=(16, 4))\n",
    "    \n",
    "    acc_keypoints_pyr = results.acc_keypoint_pyr\n",
    "    keypoints_pyr = results.initial_keypoint_pyr\n",
    "    for i, (keypoints, acc_keypoints) in enumerate(zip(keypoints_pyr, acc_keypoints_pyr)):\n",
    "        axes_before[i].imshow(sift.scaled_images[i], cmap='gray')\n",
    "        axes_after[i].imshow(sift.scaled_images[i], cmap='gray')\n",
    "        axes_before[i].scatter(keypoints[:, 2], keypoints[:, 1])\n",
    "        axes_after[i].scatter(acc_keypoints[:, 2], acc_keypoints[:, 1])\n",
    "        axes_before[i].axis('off')\n",
    "        axes_after[i].axis('off')\n",
    "        \n",
    "    fig_before.suptitle(\"Initial keypoints\", fontsize=22)\n",
    "    fig_after.suptitle(\"Keypoints after taylor approximation and contrast filter\", fontsize=22)\n",
    "    \n",
    "def plot_orientation(sift, results):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    fig.suptitle('Keypoints before and after orientation calculation', fontsize=22)\n",
    "\n",
    "    axes[0].imshow(sift.scaled_images[0], cmap='gray')\n",
    "    axes[1].imshow(sift.scaled_images[0], cmap='gray')\n",
    "\n",
    "    plot_sift_circles(results.filtered_keypoint_pyr, figure=axes[0])\n",
    "    plot_sift_circles(results.oriented_keypoint_pyr, results.orientation_pyr,  figure=axes[1])\n",
    "\n",
    "    axes[0].axis('off')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "def plot_octave(index, figsize=(16, 8)):\n",
    "    lena = load_lena()\n",
    "    dog, gs = dog_pyramid_octave(lena, index)\n",
    "    \n",
    "    images = len(gs)\n",
    "    fig, axes = plt.subplots(2, images, figsize=figsize)\n",
    "    for i, g in enumerate(gs):\n",
    "        axes[0, i].imshow(g, cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i >= 1:\n",
    "            axes[1, i].imshow(dog[i-1], cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "    fig.suptitle('Octave {}'.format(index), fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sigma(scale):\n",
    "    if scale == 0:\n",
    "        return (np.sqrt(2)) # *(octave+1)\n",
    "    else:\n",
    "        return get_sigma(scale-1)*np.sqrt(2)\n",
    "\n",
    "def print_sigmas(nb_scales=5):\n",
    "    for s in range(nb_scales):\n",
    "        sigma = get_sigma(s)\n",
    "        print(\"{:.4f}   \".format(sigma), end='')\n",
    "    print()\n",
    "    \n",
    "def dog_pyramid_octave(im, octave, nb_scales=5):\n",
    "    gaussians = []\n",
    "    for s in range(nb_scales):\n",
    "        sigma = get_sigma(s)\n",
    "        g = gaussian_filter(im, sigma, mode='mirror')\n",
    "        gaussians.append(g)\n",
    "    return np.stack([g1 - g0 for g0, g1 in pairwise(gaussians)]), np.stack(gaussians)\n",
    "\n",
    "def dog_pyramid(im, nb_octaves=3, nb_layers=5):\n",
    "    prev = im\n",
    "    dogs = []\n",
    "    for i in range(nb_octaves):\n",
    "        dog, gaussians = dog_pyramid_octave(prev, i, nb_layers)\n",
    "        prev = gaussians[-1, ::2, ::2]\n",
    "        dogs.append(dog)\n",
    "    return dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_lena(path=None):\n",
    "    if path is None:\n",
    "        lena = scipy.misc.lena() / 255\n",
    "    else:\n",
    "        lena = scipy.misc.imread(path) / 255\n",
    "    return resize(lena, np.array(lena.shape)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_num_keypoints(keypoints_pyr):\n",
    "    num_keypoints_pyr = list(map(len, keypoints_pyr))\n",
    "    print(num_keypoints_pyr)\n",
    "    print(sum(num_keypoints_pyr))\n",
    "def print_result_keys(results):\n",
    "    print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scale_space'></a>\n",
    "# Scale Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_octave(0)\n",
    "plot_octave(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT Implementation\n",
    "[Jump to the results](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_partial_derivative(tensor, i):\n",
    "    derivf = np.array([-1, 0, 1])\n",
    "    derivf = derivf / np.sum(np.abs(derivf))\n",
    "    return convolve(tensor, derivf.reshape(np.roll([1, 1, 3], i)), mode='same')\n",
    "\n",
    "def get_derivatives(dogs):\n",
    "    # partial derivatives of sigma, y and x\n",
    "    derivs = np.array([get_partial_derivative(dogs, i) for i in range(3)])\n",
    "    \n",
    "    H = np.zeros((3, 3, *dogs.shape))\n",
    "    for indices in itertools.product(range(3), repeat=2):\n",
    "        d0 = derivs[indices[0]]\n",
    "        H[indices[0], indices[1]] = get_partial_derivative(d0, indices[1])\n",
    "        \n",
    "    return H, derivs\n",
    "\n",
    "def get_neighbors(file):\n",
    "    im = skimage.color.rgb2grey(scipy.misc.imread(file))\n",
    "    im = im / np.max(im)\n",
    "    sift = SIFT(im)\n",
    "    try:\n",
    "        results = sift.get_features(descriptor_type='none')\n",
    "        padded_size = 39 // 2 \n",
    "        results.neigbhorhood_keypoint_pyr, results.neighborhood_pyr = \\\n",
    "            sift.get_neighborhoods(results.oriented_keypoint_pyr, results.orientation_pyr, padded_size)  \n",
    "        neighbours = list(filter(lambda l: len(l) > 0, results.neighborhood_pyr))\n",
    "    except ValueError as err:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    if len(neighbours) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        return np.concatenate(neighbours)\n",
    "\n",
    "def fit_sift_pca(directory, num_pca_components=20):\n",
    "    \"\"\"Fits *.jpg files in `directory`.\"\"\"\n",
    "    all_neighbours = Parallel(n_jobs=-1)(delayed(get_neighbors)(file) for file in \\\n",
    "                                        glob.glob(directory + \"/*.jpg\"))\n",
    "    all_neighbours = list(filter(lambda l: len(l) > 0, all_neighbours))\n",
    "    all_neighbours =  np.concatenate(all_neighbours)\n",
    "    pca = PCA(num_pca_components)\n",
    "    pca.fit(all_neighbours.reshape((len(all_neighbours), -1)))\n",
    "    return pca\n",
    "\n",
    "class SIFT:\n",
    "    def __init__(self, image, num_octaves=4, pca=None):\n",
    "        self.image = image\n",
    "        self.num_octaves = num_octaves\n",
    "        self.pca = pca\n",
    "        \n",
    "        self.scaled_images = [self.image]\n",
    "        self.dog_pyramid = []\n",
    "        self.gaussian_pyramid = []\n",
    "        self.hessians = []\n",
    "        self.partial_derivatives = []\n",
    "        self.image_derivatives = []\n",
    "        self._build_dogs()\n",
    "        self._build_dog_derivatives()\n",
    "        self._build_image_derivatives()\n",
    "        \n",
    "    def _build_dogs(self):\n",
    "        assert len(self.dog_pyramid) == 0\n",
    "        for i in range(self.num_octaves):\n",
    "            dogs, gs = dog_pyramid_octave(self.scaled_images[i], i)\n",
    "            assert dogs.shape[1:] == self.scaled_images[i].shape\n",
    "            self.dog_pyramid.append(dogs)\n",
    "            self.gaussian_pyramid.append(gs)\n",
    "            if i < self.num_octaves - 1:\n",
    "                self.scaled_images.append(gs[2, ::2, ::2])\n",
    "        \n",
    "    def _build_dog_derivatives(self):\n",
    "        assert len(self.hessians) == 0\n",
    "        for dogs in self.dog_pyramid:\n",
    "            H, d = get_derivatives(dogs)\n",
    "            self.hessians.append(H)\n",
    "            self.partial_derivatives.append(d)\n",
    "            \n",
    "    def _build_image_derivatives(self):\n",
    "        assert len(self.image_derivatives) == 0\n",
    "        for image in self.scaled_images:\n",
    "            self.image_derivatives.append(np.array(np.gradient(image)))\n",
    "            assert self.image_derivatives[-1][0].shape == image.shape\n",
    "            \n",
    "    def get_inital_keypoints(self):\n",
    "        def extrema(dogs):\n",
    "            return np.concatenate([peak_local_max(dogs, min_distance=1, threshold_rel=0.001),\n",
    "                                   peak_local_max(-dogs, min_distance=1, threshold_rel=0.001)])\n",
    "        \n",
    "        return [extrema(dogs) for dogs in self.dog_pyramid]\n",
    "    \n",
    "    def get_features(self, descriptor_type='sift'):\n",
    "        results = DotMap()\n",
    "        results.initial_keypoint_pyr = self.get_inital_keypoints()\n",
    "        results.acc_keypoint_pyr = self.get_accurate_keypoints(results.initial_keypoint_pyr)\n",
    "        results.filtered_keypoint_pyr = self.eliminate_edge_responses(results.acc_keypoint_pyr)\n",
    "        results.oriented_keypoint_pyr, results.orientation_pyr = \\\n",
    "            self.assign_orientations(results.filtered_keypoint_pyr)\n",
    "        \n",
    "        if descriptor_type == 'sift':\n",
    "            wsize = 16 // 2\n",
    "            dsize = 4 // 2\n",
    "            padded_size = wsize + dsize\n",
    "            results.neigbhorhood_keypoint_pyr, results.neighborhood_pyr = \\\n",
    "                self.get_neighborhoods(results.oriented_keypoint_pyr, results.orientation_pyr, padded_size)    \n",
    "            results.descriptor_point_pyr, results.descriptor_pyr = \\\n",
    "                self.get_sift_descriptors(results.neigbhorhood_keypoint_pyr, results.neighborhood_pyr)\n",
    "        elif descriptor_type == 'pca-sift':\n",
    "            assert(self.pca is not None)\n",
    "            padded_size = 39 // 2 \n",
    "            results.neigbhorhood_keypoint_pyr, results.neighborhood_pyr = \\\n",
    "                self.get_neighborhoods(results.oriented_keypoint_pyr, results.orientation_pyr, padded_size)  \n",
    "            results.descriptor_point_pyr, results.descriptor_pyr = \\\n",
    "                self.get_pca_sift_descriptors(results.neigbhorhood_keypoint_pyr, results.neighborhood_pyr)\n",
    "        return results\n",
    "        \n",
    "    def get_accurate_keypoints(self, keypoint_pyr):\n",
    "        acc_keypoints_pyr = []\n",
    "        for i, keypoints in enumerate(keypoint_pyr):\n",
    "            acc_keypoints = self._get_accurate_keypoints(keypoints, i)\n",
    "            acc_keypoints_pyr.append(acc_keypoints)\n",
    "        return acc_keypoints_pyr\n",
    "\n",
    "    def _get_accurate_keypoints(self, extrema, pyramid_level, finalized_extrema=None, num_iteration=0):\n",
    "        def shift(e, offset):\n",
    "            return np.round(e + offset).astype('int')\n",
    "\n",
    "        def in_bounds(p):\n",
    "            try:\n",
    "                H[:, :, p[0], p[1], p[2]]\n",
    "                return True\n",
    "            except IndexError:\n",
    "                return False\n",
    "\n",
    "        def has_sufficent_constrast(point, offset, threshold=0.03):\n",
    "            p = point\n",
    "            D = dogs[tuple(point)]\n",
    "            d = derivs[:, p[0], p[1], p[2]]\n",
    "            contrast = D + 0.5 * d.T @ offset\n",
    "            return np.abs(contrast) > threshold\n",
    "\n",
    "        def is_extrema(point, offset, max_iterations=20):\n",
    "            shift_point = shift(point, offset) \n",
    "            return (num_iteration >= max_iterations or \\\n",
    "                np.all(shift_point == point) or \\\n",
    "                np.min(shift_point) < 0) and \\\n",
    "                in_bounds(shift_point)               \n",
    "\n",
    "        def get_taylor_offset(p):\n",
    "            h = H[:, :, p[0], p[1], p[2]]\n",
    "            d = derivs[:, p[0], p[1], p[2]]\n",
    "            return -np.linalg.pinv(h) @ d.T\n",
    "        \n",
    "        H = self.hessians[pyramid_level]\n",
    "        derivs = self.partial_derivatives[pyramid_level]\n",
    "        dogs = self.dog_pyramid[pyramid_level]\n",
    "\n",
    "        if finalized_extrema is None:\n",
    "            finalized_extrema = []\n",
    "        if len(extrema) == 0:\n",
    "            return np.array(finalized_extrema)\n",
    "\n",
    "        modified_extrema = []\n",
    "        for point in extrema:\n",
    "            offset = get_taylor_offset(point)\n",
    "            if is_extrema(point, offset):\n",
    "                if has_sufficent_constrast(point, offset):\n",
    "                    finalized_extrema.append(point)\n",
    "            else:\n",
    "                shift_point = shift(point, offset) \n",
    "                if in_bounds(shift_point):\n",
    "                    modified_extrema.append(shift_point)       \n",
    "        if not modified_extrema:\n",
    "            return np.array(finalized_extrema)\n",
    "        return self._get_accurate_keypoints(modified_extrema, pyramid_level, finalized_extrema, num_iteration + 1)  \n",
    "    \n",
    "    def eliminate_edge_responses(self, keypoint_pyr, r=10.):\n",
    "        remaining_point_pyr = []\n",
    "        for pyramid_level, keypoints in enumerate(keypoint_pyr):\n",
    "            H = self.hessians[pyramid_level][:2, :2]\n",
    "            \n",
    "            remaining_points = []\n",
    "            for point in keypoints:\n",
    "                h = H[:, :, point[0], point[1], point[2]]\n",
    "                c = (np.trace(h)**2) / np.linalg.det(h)\n",
    "                \n",
    "                if c < (r + 1)**2 / r:\n",
    "                    remaining_points.append(point)        \n",
    "            remaining_point_pyr.append(np.array(remaining_points))\n",
    "        return remaining_point_pyr\n",
    "    \n",
    "    def assign_orientations(self, keypoint_pyr, num_bins=36):\n",
    "        def get_window_center(slicex, slicey, point):\n",
    "            def get_center(sl):\n",
    "                return np.argmin(np.abs(np.array(range(sl.start, sl.stop))))\n",
    "            return get_center(slicex) + point[1], get_center(slicey) + point[2]\n",
    "\n",
    "        oriented_keypoint_pyr = []\n",
    "        orientation_pyr = []\n",
    "        for pyramid_level, (keypoints, image) in enumerate(zip(keypoint_pyr, self.image_derivatives)):\n",
    "            oriented_keypoints = []\n",
    "            orientations = []\n",
    "            for point in keypoints:\n",
    "                sigma = 1.5 * get_sigma(point[0])\n",
    "                wsize = int(sigma * 3 / 2)\n",
    "\n",
    "                sx = slice(max(0, point[1] - wsize), min(image.shape[1], point[1] + wsize + 1))\n",
    "                sy = slice(max(0, point[2] - wsize), min(image.shape[2], point[2] + wsize + 1))\n",
    "\n",
    "                gradx = image[0, sx, sy]\n",
    "                grady = image[1, sx, sy]\n",
    "\n",
    "                centerx, centery = get_window_center(sx, sy, point)\n",
    "\n",
    "                gradient = np.sqrt(gradx**2 + grady**2)\n",
    "                theta = np.arctan2(grady, gradx)\n",
    "\n",
    "                gaussianx = scipy.stats.norm(centerx, sigma).pdf(range(sx.start, sx.stop))\n",
    "                gaussiany = scipy.stats.norm(centery, sigma).pdf(range(sy.start, sy.stop))\n",
    "                gaussian = gaussianx[:, np.newaxis] @ gaussiany[:, np.newaxis].T            \n",
    "\n",
    "                bins, _ = np.histogram(theta, weights=gaussian * gradient, bins=num_bins, range=(-np.pi, np.pi))\n",
    "\n",
    "                highest_peak = max(bins)\n",
    "                indices = np.nonzero(bins >= 0.8 * highest_peak)[0]\n",
    "\n",
    "                for idx in indices:\n",
    "                    x = np.array(range(idx-1, idx+2))\n",
    "                    y = bins[x % num_bins] \n",
    "\n",
    "                    coeffs = np.polyfit(x, y, deg=2)\n",
    "                    parabola_fit = -coeffs[1] / (2 * coeffs[0])\n",
    "                    assert(not(np.any(np.isnan(parabola_fit))))\n",
    "\n",
    "                    oriented_keypoints.append(point)\n",
    "                    orientations.append((parabola_fit - 0.5 * num_bins) / (0.5 * num_bins) * np.pi)\n",
    "\n",
    "            oriented_keypoint_pyr.append(np.array(oriented_keypoints))\n",
    "            orientation_pyr.append(np.array(orientations))\n",
    "        return oriented_keypoint_pyr, orientation_pyr\n",
    "    \n",
    "    def get_neighborhoods(self, keypoint_pyr, orientation_pyr, padded_size):\n",
    "        def in_bounds(p, image):\n",
    "            try:\n",
    "                image[p[0], p[1]]\n",
    "                if np.min(p) >= 0:\n",
    "                    return True\n",
    "                return False\n",
    "            except IndexError:\n",
    "                return False\n",
    "\n",
    "        def get_rotated_subwindows(image, orientation, sx, sy, ds):\n",
    "            rotated = rotate(image[sx, sy], orientation/np.pi*180)\n",
    "            assert(rotated.shape == image[sx, sy].shape)\n",
    "            gradx, grady = np.gradient(rotated[ds, ds])\n",
    "            return gradx, grady\n",
    "\n",
    "        rotbox_size = int(np.ceil(padded_size * np.sqrt(2)))\n",
    "                \n",
    "        descriptor_pyr = []\n",
    "        point_pyr = []\n",
    "        for pyramid_level, (keypoints, orients, octave) in \\\n",
    "                enumerate(zip(keypoint_pyr, orientation_pyr, self.gaussian_pyramid)):\n",
    "            descriptors = []\n",
    "            points = []\n",
    "            for point, point_orientation in zip(keypoints, orients):\n",
    "                image = octave[point[0]]\n",
    "                assert(not(np.any(np.isnan(image))))                \n",
    "                sx = slice(point[1] - rotbox_size, point[1] + rotbox_size + 1)\n",
    "                sy = slice(point[2] - rotbox_size, point[2] + rotbox_size + 1)\n",
    "                \n",
    "                if np.any([not(in_bounds(p, image)) for p in ((sx.start, sy.start), (sx.stop - 1, sy.stop - 1))]):\n",
    "                    continue\n",
    "\n",
    "                ds = slice(rotbox_size - padded_size, rotbox_size + padded_size)\n",
    "                \n",
    "                gradx, grady = get_rotated_subwindows(image, -point_orientation, sx, sy, ds)\n",
    "                descriptors.append(np.stack((gradx, grady)))\n",
    "                points.append(point)\n",
    "            if descriptors:\n",
    "                descriptor_pyr.append(np.stack(descriptors))\n",
    "            else:\n",
    "                descriptor_pyr.append([])\n",
    "            \n",
    "            point_pyr.append(np.array(points))\n",
    "        return point_pyr, descriptor_pyr\n",
    "    \n",
    "    def get_sift_descriptors(self, keypoint_pyr, gradient_pyr, num_bins=8, wsize=16//2, dsize=4):       \n",
    "        def get_odd_linear_kernel(size):\n",
    "            return np.array([max(0, (1 - abs(d) / size)) for d in np.arange(-size, size+1, 1)])[:, np.newaxis]\n",
    "\n",
    "        def get_even_linear_kernel(size):\n",
    "            return np.array([max(0, (1 - abs(d) / size)) for d in np.arange(-size+0.5, size, 1)])[:, np.newaxis]\n",
    "        \n",
    "        bin_kernel = get_even_linear_kernel(dsize) @ get_even_linear_kernel(dsize).T\n",
    "        \n",
    "        def normalize(vec):\n",
    "            vec = vec / np.linalg.norm(vec)\n",
    "            vec = np.minimum(0.2, vec)\n",
    "            return vec / np.linalg.norm(vec)\n",
    "\n",
    "        hist_kernel = get_odd_linear_kernel(num_bins//2)\n",
    "        \n",
    "        padded_size = wsize + dsize // 2\n",
    "        gaussianx = scipy.stats.norm(0, wsize).pdf(range(-padded_size, padded_size))\n",
    "        gaussiany = scipy.stats.norm(0, wsize).pdf(range(-padded_size, padded_size))\n",
    "        gaussian = gaussianx[:, np.newaxis] @ gaussiany[:, np.newaxis].T\n",
    "        \n",
    "        descriptor_pyr = []\n",
    "        point_pyr = []\n",
    "        for pyramid_level, (keypoints, gradients, octave) in \\\n",
    "                enumerate(zip(keypoint_pyr, gradient_pyr, self.gaussian_pyramid)):\n",
    "            descriptors = []\n",
    "            points = []         \n",
    "            for point, gradient in zip(keypoints, gradients):\n",
    "                gradx = gradient[0]\n",
    "                grady = gradient[1]\n",
    "\n",
    "                magnitude = np.sqrt(gradx**2 + grady**2) * gaussian\n",
    "                theta = np.arctan2(grady, gradx)\n",
    "\n",
    "                point_descriptors = []\n",
    "                for fromx in np.arange(0, wsize*2, dsize):\n",
    "                    for fromy in np.arange(0, wsize*2, dsize):\n",
    "\n",
    "                        sx = slice(fromx, fromx+2*dsize)\n",
    "                        sy = slice(fromy, fromy+2*dsize)\n",
    "\n",
    "                        window_magnitude = magnitude[sx, sy] * bin_kernel\n",
    "                        window_theta = theta[sx, sy]\n",
    "\n",
    "                        bins, _ = np.histogram(window_theta, weights=window_magnitude, \n",
    "                                               bins=num_bins, range=(-np.pi, np.pi))\n",
    "                        bins = scipy.ndimage.convolve(bins, hist_kernel.flatten(), mode='wrap')\n",
    "                        \n",
    "                        point_descriptors.append(bins)\n",
    "                point_descriptors = np.concatenate(point_descriptors)\n",
    "                descriptors.append(normalize(point_descriptors))\n",
    "                points.append(point)\n",
    "            descriptor_pyr.append(np.array(descriptors))\n",
    "            point_pyr.append(np.array(points))\n",
    "        return point_pyr, descriptor_pyr\n",
    "    \n",
    "    def get_pca_sift_descriptors(self, keypoint_pyr, gradient_pyr):\n",
    "        def process_pyramid_level(keypoints, gradients):\n",
    "            gradients = np.stack(gradients).reshape(len(gradients), -1)\n",
    "            descriptors = self.pca.transform(gradients)\n",
    "            return keypoints, descriptors\n",
    "        \n",
    "        point_pyr, descriptor_pyr = zip(*list(map(lambda x: process_pyramid_level(*x), \n",
    "                                             zip(keypoint_pyr, gradient_pyr))))\n",
    "            \n",
    "        return point_pyr, descriptor_pyr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "# Keypoint detection, taylor approximation and contrast filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lena = load_lena()\n",
    "sift = SIFT(lena)\n",
    "lena_results = sift.get_features(descriptor_type='sift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_initial_keypoints(sift, lena_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_num_keypoints(lena_results.initial_keypoint_pyr)\n",
    "print_num_keypoints(lena_results.filtered_keypoint_pyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "fig.suptitle('Keypoints before and after taylor approximation and contrast filter', fontsize=22)\n",
    "\n",
    "axes[0].imshow(lena, cmap='gray')\n",
    "axes[1].imshow(lena, cmap='gray')\n",
    "\n",
    "plot_sift_circles(lena_results.initial_keypoint_pyr, figure=axes[0])\n",
    "plot_sift_circles(lena_results.acc_keypoint_pyr, figure=axes[1])\n",
    "\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge response elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.suptitle('Keypoints before and after edge response elimination', fontsize=22)\n",
    "\n",
    "axes[0].imshow(lena, cmap='gray')\n",
    "axes[1].imshow(lena, cmap='gray')\n",
    "\n",
    "plot_sift_circles(lena_results.acc_keypoint_pyr, figure=axes[0])\n",
    "plot_sift_circles(lena_results.filtered_keypoint_pyr, figure=axes[1])\n",
    "\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orientation calculation and parabola fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_orientation(sift, lena_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lena_transformed = load_lena('Lenna_transformed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(lena_transformed, cmap=plt.cm.gray)\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_sift = SIFT(lena_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_results = transformed_sift.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_orientation(sift, results, figsize=(16, 8)):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    fig.suptitle('Keypoints before and after orientation calculation', fontsize=22)\n",
    "\n",
    "    axes[0].imshow(sift.scaled_images[0], cmap='gray')\n",
    "    axes[1].imshow(sift.scaled_images[0], cmap='gray')\n",
    "\n",
    "    plot_sift_circles(results.filtered_keypoint_pyr, figure=axes[0])\n",
    "    plot_sift_circles(results.oriented_keypoint_pyr, results.orientation_pyr,  figure=axes[1])\n",
    "\n",
    "    axes[0].axis('off')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "plot_orientation(sift, lena_results)\n",
    "plt.show()\n",
    "plot_orientation(transformed_sift, transformed_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sift_matching(first, second, threshold=0.7):\n",
    "    first_descriptors = np.concatenate(first.descriptor_pyr)\n",
    "    second_descriptors = np.concatenate(second.descriptor_pyr)\n",
    "    \n",
    "    matches = OrderedDict()\n",
    "    distances = np.zeros((first_descriptors.shape[0], second_descriptors.shape[0]))\n",
    "    for i, first_descriptor in enumerate(first_descriptors):\n",
    "        distances[i] = np.linalg.norm(second_descriptors - first_descriptor, axis=1)\n",
    "    \n",
    "    while True:\n",
    "        def unravel(idx):\n",
    "            return np.unravel_index(idx, distances.shape)\n",
    "\n",
    "        def ratio(distances):\n",
    "            return distances[0] / distances[1]\n",
    "        \n",
    "        rows = np.argpartition(distances, 2, axis=1)[:, :2]\n",
    "        dists = np.array([(distances[r, rows[r, 0]], distances[r, rows[r, 1]]) for r in range(len(rows))])\n",
    "        ratios = dists[:, 0] / dists[:, 1]\n",
    "        ratios[np.isnan(ratios)] = np.inf\n",
    "        bestidx = np.argmin(ratios)\n",
    "        \n",
    "        if ratios[bestidx] < threshold:\n",
    "            i = bestidx\n",
    "            j = rows[bestidx][0]\n",
    "            distances[i, :] = np.inf\n",
    "            distances[:, j] = np.inf\n",
    "            matches[i] = j\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_matching_dict(first_sift, second_sift, first_results, second_results, matching_dict, nbest=25):\n",
    "    def matching_points(matching_dict):\n",
    "        first_descriptors = np.concatenate(scale_points_pyramid(first_results.descriptor_point_pyr))\n",
    "        second_descriptors = np.concatenate(scale_points_pyramid(second_results.descriptor_point_pyr))\n",
    "        first_index = np.array(list(matching_dict.keys()))\n",
    "        second_index = np.array(list(matching_dict.values()))\n",
    "        return list(zip(first_descriptors[first_index], second_descriptors[second_index]))\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax1.imshow(first_sift.scaled_images[0], cmap=plt.cm.gray)\n",
    "    ax2.imshow(second_sift.scaled_images[0], cmap=plt.cm.gray)\n",
    "    plot_sift_circles(first_results.oriented_keypoint_pyr, first_results.orientation_pyr, figure=ax1)\n",
    "    plot_sift_circles(second_results.oriented_keypoint_pyr, second_results.orientation_pyr, figure=ax2)\n",
    "    \n",
    "    assert np.min(np.concatenate(second_results.descriptor_point_pyr)) >= 0\n",
    "    def matching_line(p1, p2):\n",
    "        con = lambda: ConnectionPatch([p1[2], p1[1]], [p2[2], p2[1]],  coordsA=\"data\", coordsB=\"data\", \n",
    "                                       arrowstyle=\"<-\", alpha=0.75, ec=sns.color_palette()[4], lw=3,\n",
    "                                       axesA=ax2, axesB=ax1)\n",
    "        ax2.add_artist(con())\n",
    "    \n",
    "    for f, s in islice(matching_points(matching_dict), nbest):\n",
    "        matching_line(s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matching_dict = sift_matching(lena_results, transformed_results)\n",
    "plot_matching_dict(sift, transformed_sift, lena_results, transformed_results, matching_dict, nbest=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint matching using PCA-SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = fit_sift_pca('pca_train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"pca.pickle\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_pca_sift = SIFT(lena_transformed, pca=pca)\n",
    "trans_pca_res = trans_pca_sift.get_features('pca-sift')\n",
    "pca_lena = SIFT(lena, pca=pca)\n",
    "pca_lena_res = pca_lena.get_features('pca-sift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matching_dict = sift_matching(pca_lena_res, trans_pca_res)\n",
    "plot_matching_dict(pca_lena, trans_pca_sift, pca_lena_res, trans_pca_res, matching_dict)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
