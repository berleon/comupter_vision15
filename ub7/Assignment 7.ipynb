{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import solve\n",
    "import base64\n",
    "import math\n",
    "\n",
    "from skimage.filters import gaussian_filter, scharr_h, scharr_v\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.transform import resize\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "import scipy.misc\n",
    "from scipy.signal import convolve\n",
    "\n",
    "import itertools\n",
    "from itertools import tee, islice\n",
    "import imageio\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from more_itertools import pairwise\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sigma(scale):\n",
    "    if scale == 0:\n",
    "        return (np.sqrt(2)) # *(octave+1)\n",
    "    else:\n",
    "        return get_sigma(scale-1)*np.sqrt(2)\n",
    "\n",
    "def dog_pyramid_octave(im, octave, nb_scales=5):\n",
    "    gaussians = []\n",
    "    for s in range(nb_scales):\n",
    "        sigma = get_sigma(s)\n",
    "        print(\"{:.4f}   \".format(sigma), end='')\n",
    "        g = gaussian_filter(im, sigma, mode='mirror')\n",
    "        gaussians.append(g)\n",
    "    print()\n",
    "    return np.stack([g1 - g0 for g0, g1 in pairwise(gaussians)]), np.stack(gaussians)\n",
    "\n",
    "def dog_pyramid(im, nb_octaves=3, nb_layers=5):\n",
    "    prev = im\n",
    "    dogs = []\n",
    "    for i in range(nb_octaves):\n",
    "        dog, gaussians = dog_pyramid_octave(prev, i, nb_layers)\n",
    "        prev = gaussians[-1, ::2, ::2]\n",
    "        dogs.append(dog)\n",
    "    return dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_lena():\n",
    "    lena = scipy.misc.lena() / 255\n",
    "    return resize(lena, np.array(lena.shape)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lena = load_lena()\n",
    "dog, gs = dog_pyramid_octave(lena, 0)\n",
    "\n",
    "for i, g in enumerate(gs):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(g, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i >= 1:\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(dog[i-1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_partial_derivative(tensor, i):\n",
    "    derivf = np.array([-1, 0, 1])\n",
    "    derivf = derivf / np.sum(np.abs(derivf))\n",
    "    return convolve(tensor, derivf.reshape(np.roll([1, 1, 3], i)), mode='same')\n",
    "\n",
    "def get_derivatives(dogs):\n",
    "    # partial derivatives of sigma, y and x\n",
    "    derivs = np.array([get_partial_derivative(dogs, i) for i in range(3)])\n",
    "    \n",
    "    H = np.zeros((3, 3, *dogs.shape))\n",
    "    for indices in itertools.product(range(3), repeat=2):\n",
    "        d0 = derivs[indices[0]]\n",
    "        H[indices[0], indices[1]] = get_partial_derivative(d0, indices[1])\n",
    "        \n",
    "    return H, derivs\n",
    "\n",
    "class SIFT:\n",
    "    def __init__(self, image, num_octaves=4):\n",
    "        self.image = image\n",
    "        self.num_octaves = num_octaves\n",
    "        \n",
    "        self.scaled_images = [self.image]\n",
    "        self.dog_pyramid = []\n",
    "        self.gaussian_pyramid = []\n",
    "        self.hessians = []\n",
    "        self.partial_derivatives = []\n",
    "        self._build_dogs()\n",
    "        self._build_derivatives()\n",
    "        \n",
    "    def _build_dogs(self):\n",
    "        assert len(self.dog_pyramid) == 0\n",
    "        for i in range(self.num_octaves):\n",
    "            dogs, gs = dog_pyramid_octave(self.scaled_images[i], i)\n",
    "            self.dog_pyramid.append(dogs)\n",
    "            self.gaussian_pyramid.append(gs)\n",
    "            if i < self.num_octaves - 1:\n",
    "                self.scaled_images.append(gs[2, ::2, ::2])\n",
    "        \n",
    "    def _build_derivatives(self):\n",
    "        assert len(self.hessians) == 0\n",
    "        for dogs in self.dog_pyramid:\n",
    "            H, d = get_derivatives(dogs)\n",
    "            self.hessians.append(H)\n",
    "            self.partial_derivatives.append(d)\n",
    "            \n",
    "    def get_inital_keypoints(self):\n",
    "        def extrema(dogs):\n",
    "            return np.concatenate([peak_local_max(dogs, min_distance=1, threshold_rel=0.), \n",
    "                                   peak_local_max(-dogs, min_distance=1, threshold_rel=0.)])\n",
    "        \n",
    "        return [extrema(dogs) for dogs in self.dog_pyramid]\n",
    "    \n",
    "    def get_accurate_keypoints(self, extrema, pyramid_level, finalized_extrema=None, num_iteration=0):\n",
    "        def shift(e, offset):\n",
    "            return np.round(e + offset).astype('int')\n",
    "\n",
    "        def in_bounds(p):\n",
    "            try:\n",
    "                H[:, :, p[0], p[1], p[2]]\n",
    "                return True\n",
    "            except IndexError:\n",
    "                return False\n",
    "\n",
    "        def has_sufficent_constrast(point, offset, threshold=0.03):\n",
    "            p = point\n",
    "            D = dogs[tuple(point)]\n",
    "            d = derivs[:, p[0], p[1], p[2]]\n",
    "            contrast = D + 0.5 * d.T @ offset\n",
    "            return np.abs(contrast) > threshold\n",
    "\n",
    "        def is_extrema(point, offset, max_iterations=20):\n",
    "            shift_point = shift(point, offset) \n",
    "            return (num_iteration >= max_iterations or \\\n",
    "                np.all(shift_point == point) or \\\n",
    "                np.min(shift_point) < 0) and \\\n",
    "                in_bounds(shift_point)               \n",
    "\n",
    "        def get_taylor_offset(p):\n",
    "            h = H[:, :, p[0], p[1], p[2]]\n",
    "            d = derivs[:, p[0], p[1], p[2]]\n",
    "            return -np.linalg.pinv(h) @ d.T\n",
    "        \n",
    "        H = self.hessians[pyramid_level]\n",
    "        derivs = self.partial_derivatives[pyramid_level]\n",
    "        dogs = self.dog_pyramid[pyramid_level]\n",
    "\n",
    "        if finalized_extrema is None:\n",
    "            finalized_extrema = []\n",
    "        if len(extrema) == 0:\n",
    "            return np.array(finalized_extrema)\n",
    "\n",
    "        modified_extrema = []\n",
    "        for point in extrema:\n",
    "            offset = get_taylor_offset(point)\n",
    "            if is_extrema(point, offset):\n",
    "                if has_sufficent_constrast(point, offset):\n",
    "                    finalized_extrema.append(point)\n",
    "            else:\n",
    "                shift_point = shift(point, offset) \n",
    "                if in_bounds(shift_point):\n",
    "                    modified_extrema.append(shift_point)       \n",
    "        if not modified_extrema:\n",
    "            return np.array(finalized_extrema)\n",
    "        return self.get_accurate_keypoints(modified_extrema, pyramid_level, finalized_extrema, num_iteration + 1)  \n",
    "    \n",
    "    def eliminate_edge_responses(self, keypoint_pyr, r=10.):\n",
    "        remaining_point_pyr = []\n",
    "        for pyramid_level, keypoints in enumerate(keypoint_pyr):\n",
    "            H = self.hessians[pyramid_level][:2, :2]\n",
    "            \n",
    "            remaining_points = []\n",
    "            for point in keypoints:\n",
    "                h = H[:, :, point[0], point[1], point[2]]\n",
    "                c = (np.trace(h)**2) / np.linalg.det(h)\n",
    "                \n",
    "                if c < (r + 1)**2 / r:\n",
    "                    remaining_points.append(point)        \n",
    "            remaining_point_pyr.append(np.array(remaining_points))\n",
    "        return remaining_point_pyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lena = load_lena()\n",
    "num_octaves = 5\n",
    "sift = SIFT(lena, num_octaves)\n",
    "\n",
    "fig, axes = plt.subplots(2, num_octaves, figsize=(16, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "acc_keypoints_pyr = []\n",
    "keypoints_pyr = sift.get_inital_keypoints()\n",
    "for i, keypoints in enumerate(keypoints_pyr):\n",
    "    acc_keypoints = sift.get_accurate_keypoints(keypoints, i)\n",
    "    acc_keypoints_pyr.append(acc_keypoints)\n",
    "    axes[0, i].imshow(sift.scaled_images[i], cmap='gray')\n",
    "    axes[1, i].imshow(sift.scaled_images[i], cmap='gray')\n",
    "    axes[0, i].scatter(keypoints[:, 2], keypoints[:, 1])\n",
    "    axes[1, i].scatter(acc_keypoints[:, 2], acc_keypoints[:, 1])\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "axes[0, num_octaves // 2].set_title(\"Initial keypoints\", fontsize=22)\n",
    "_ = axes[1, num_octaves // 2].set_title(\"Keypoints after taylor approximation and contrast filter\", fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_num_keypoints(keypoints_pyr):\n",
    "    num_keypoints_pyr = list(map(len, keypoints_pyr))\n",
    "    print(num_keypoints_pyr)\n",
    "    print(sum(num_keypoints_pyr))\n",
    "    \n",
    "print_num_keypoints(keypoints_pyr)\n",
    "print_num_keypoints(acc_keypoints_pyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Keypoints before and after taylor approximation and contrast filter', fontsize=22)\n",
    "\n",
    "axes[0].imshow(lena, cmap='gray')\n",
    "axes[1].imshow(lena, cmap='gray')\n",
    "\n",
    "def scale_points(points, s):\n",
    "    return points * (2 ** s)\n",
    "\n",
    "for s, (keypoints, acc_keypoints)  in enumerate(zip(keypoints_pyr, acc_keypoints_pyr)):\n",
    "    keypoints_scaled = scale_points(keypoints, s)\n",
    "    acc_keypoints_scaled = scale_points(acc_keypoints, s)\n",
    "    axes[0].scatter(keypoints_scaled[:, 2], keypoints_scaled[:, 1])\n",
    "    axes[1].scatter(acc_keypoints_scaled[:, 2], acc_keypoints_scaled[:, 1])\n",
    "    axes[0].axis('off')\n",
    "    axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Keypoints before and after edge response elimination', fontsize=22)\n",
    "\n",
    "axes[0].imshow(lena, cmap='gray')\n",
    "axes[1].imshow(lena, cmap='gray')\n",
    "\n",
    "def scale_points(points, s):\n",
    "    return points * (2 ** s)\n",
    "\n",
    "filtered_keypoints_pyr = sift.eliminate_edge_responses(acc_keypoints_pyr)\n",
    "print_num_keypoints(acc_keypoints_pyr)\n",
    "print_num_keypoints(filtered_keypoints_pyr)\n",
    "\n",
    "for s, (keypoints, filtered_keypoints)  in enumerate(zip(acc_keypoints_pyr, filtered_keypoints_pyr)):\n",
    "    keypoints_scaled = scale_points(keypoints, s)\n",
    "    filtered_keypoints_scaled = scale_points(filtered_keypoints, s)\n",
    "    axes[0].scatter(keypoints_scaled[:, 2], keypoints_scaled[:, 1])\n",
    "    axes[1].scatter(filtered_keypoints_scaled[:, 2], filtered_keypoints_scaled[:, 1])\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_orientations(keypoint_pyr, num_bins=36):\n",
    "    image_derivatives = []\n",
    "    for image in sift.scaled_images:\n",
    "        image_derivatives.append(np.array((scharr_h(image), scharr_v(image))))\n",
    "        \n",
    "    def get_window_center(slicex, slicey, point):\n",
    "        def get_center(sl, point):\n",
    "            return np.argmin(np.abs(np.array(range(sl.start, sl.stop)) - point))\n",
    "        return get_center(slicex, point[1]), get_center(slicey, point[2])\n",
    "    \n",
    "    oriented_keypoint_pyr = []\n",
    "    for pyramid_level, (keypoints, image) in enumerate(zip(keypoint_pyr, image_derivatives)):\n",
    "        oriented_keypoints = []\n",
    "        for point in keypoints:\n",
    "            sigma = 1.5 * get_sigma(point[0])\n",
    "            wsize = int(sigma * 3 / 2)\n",
    "            \n",
    "            sx = slice(max(0, point[1] - wsize), min(image.shape[1], point[1] + wsize + 1))\n",
    "            sy = slice(max(0, point[2] - wsize), min(image.shape[2], point[2] + wsize + 1))\n",
    "            \n",
    "            gradx = image[0, sx, sy]\n",
    "            grady = image[1, sx, sy]\n",
    "            \n",
    "            centerx, centery = get_window_center(sx, sy, point)\n",
    "            \n",
    "            gradient = np.sqrt(gradx**2 + grady**2)\n",
    "            theta = np.arctan2(grady, gradx)\n",
    "            \n",
    "            gaussianx = scipy.stats.norm(point[1], sigma).pdf(range(sx.start, sx.stop))\n",
    "            gaussiany = scipy.stats.norm(point[2], sigma).pdf(range(sy.start, sy.stop))\n",
    "            gaussian = gaussianx[:, np.newaxis] @ gaussiany[:, np.newaxis].T            \n",
    "            \n",
    "            bins, _ = np.histogram(theta, weights=gaussian * gradient, bins=num_bins, range=(-np.pi, np.pi))\n",
    "            \n",
    "            highest_peak = max(bins)\n",
    "            indices = np.nonzero(bins >= 0.8 * highest_peak)[0]\n",
    "            \n",
    "            for idx in indices:\n",
    "                x = np.array(range(idx-1, idx+2))\n",
    "                y = bins[x % num_bins]              \n",
    "                coeffs = np.polyfit(x, y, deg=2)\n",
    "                parabola_fit = -coeffs[1] / (2 * coeffs[0])\n",
    "                \n",
    "                # TODO: cleanup\n",
    "                oriented_keypoints.append((point[0], point[1], point[2], \n",
    "                                           (parabola_fit - 0.5 * num_bins) / (0.5 * num_bins) * np.pi))\n",
    "            \n",
    "        oriented_keypoint_pyr.append(np.array(oriented_keypoints))\n",
    "    return oriented_keypoint_pyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oriented_keypoints_pyr = assign_orientations(filtered_keypoints_pyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Keypoints before and after edge response elimination', fontsize=22)\n",
    "\n",
    "axes[0].imshow(lena, cmap='gray')\n",
    "axes[1].imshow(lena, cmap='gray')\n",
    "\n",
    "def scale_points(points, s):\n",
    "    if points.shape[1] == 3:\n",
    "        return points * (2 ** s)\n",
    "    return points[:, :3] * (2 ** s), points[:, 3]\n",
    "\n",
    "for s, (filtered_keypoints, oriented_keypoints)  in enumerate(zip(filtered_keypoints_pyr, oriented_keypoints_pyr)):\n",
    "    filtered_keypoints_scaled = scale_points(filtered_keypoints, s)\n",
    "    oriented_keypoints_scaled, oriented_thetas = scale_points(oriented_keypoints, s)\n",
    "    \n",
    "    axes[0].scatter(filtered_keypoints_scaled[:, 2], filtered_keypoints_scaled[:, 1])\n",
    "    axes[1].scatter(oriented_keypoints_scaled[:, 2], oriented_keypoints_scaled[:, 1])\n",
    "    \n",
    "    axes[1].quiver(oriented_keypoints_scaled[:, 2], oriented_keypoints_scaled[:, 1],\n",
    "                   np.sin(oriented_thetas) * 1.7**s, np.cos(oriented_thetas) * 1.7**s, \n",
    "                   width=0.005, scale=50, color='blue', alpha=0.25)\n",
    "    \n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
